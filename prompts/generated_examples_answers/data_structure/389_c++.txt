c++
```cpp
#include <list>
#include <unordered_map>
#include <stdexcept>

template <typename K, typename V>
class LRUCache {
public:
    explicit LRUCache(size_t capacity) : cap_(capacity) {
        if (capacity == 0) throw std::invalid_argument("capacity must be > 0");
    }

    V get(const K& key) {
        auto it = map_.find(key);
        if (it == map_.end()) throw std::out_of_range("miss");
        touch(it);
        return it->second.first;
    }

    void put(const K& key, const V& value) {
        auto it = map_.find(key);
        if (it != map_.end()) {
            it->second.first = value;
            touch(it);
            return;
        }
        if (map_.size() == cap_) {
            K lru = order_.back();
            order_.pop_back();
            map_.erase(lru);
        }
        order_.push_front(key);
        map_[key] = {value, order_.begin()};
    }

private:
    void touch(typename std::unordered_map<K, std::pair<V, typename std::list<K>::iterator>>::iterator it) {
        order_.erase(it->second.second);
        order_.push_front(it->first);
        it->second.second = order_.begin();
    }

    size_t cap_;
    std::list<K> order_;
    std::unordered_map<K, std::pair<V, typename std::list<K>::iterator>> map_;
};
```
**Explanation:** Combines an unordered_map for O(1) lookups with a list for recency tracking. On get/put, moves the key to the front; when capacity is exceeded, evicts the least-recently used key from the back.
**Complexity:** Time: O(1) average per op; Space: O(capacity).
**Example:**
Input: cap=2; put(1,"a"); put(2,"b"); get(1); put(3,"c")
Output: key 2 evicted; cache holds 1,3
**Notes:**
- Throws on misses; return sentinel if preferred.
- Thread-safety not provided; add locks for concurrent use.
- Template supports any hashable key type.
