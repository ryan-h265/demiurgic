# Demiurgic Requirements
#
# For quick start (model architecture only):
#   pip install -r requirements-core.txt
#
# For full training setup:
#   pip install -r requirements-core.txt
#   pip install -r requirements-training.txt
#
# For Flash Attention 2 (optional, 2-4x speedup, requires CUDA):
#   pip install flash-attn --no-build-isolation
#
# Or install everything:
#   pip install -r requirements.txt

# Core dependencies - Always needed
torch>=2.0.0
numpy>=1.24.0
llama-cpp-python>=0.2.90
pytest>=7.4.0

# Training infrastructure - Needed for actual training
transformers>=4.35.0
tokenizers>=0.14.0
accelerate>=0.24.0
datasets>=2.14.0
tqdm>=4.66.0
pyyaml>=6.0.0
einops>=0.7.0

# API providers for data generation - Needed for cloud-based teachers
anthropic>=0.7.0
openai>=1.0.0
tiktoken>=0.5.0
aiohttp>=3.9.0
peft>=0.7.0

# Experiment tracking
wandb>=0.15.0
tensorboard>=2.14.0

# Development
black>=23.0.0
isort>=5.12.0

# CLI/TUI interface
rich>=13.0.0
prompt-toolkit>=3.0.0
pygments>=2.16.0

# Optional: DeepSpeed (for multi-GPU training)
# deepspeed>=0.12.0

# Optional: Flash Attention 2 (requires CUDA, install separately)
# flash-attn>=2.0.0
